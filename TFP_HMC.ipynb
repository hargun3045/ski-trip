{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding HMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import pandas as pd\n",
    "import tensorflow.compat.v2 as tf\n",
    "tf.enable_v2_behavior()\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not sure why I imported this\n",
    "import scipy.stats as ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Viz. \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import seaborn as sns\n",
    "sns_c = sns.color_palette(palette='pastel')\n",
    "%matplotlib inline\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Distribution\n",
    "\n",
    "Here we define a *True* process, which we want to estimate.\n",
    "The true process is: \n",
    "\n",
    "1. A poisson distribution\n",
    "2. with lambda value $\\lambda$ = 2\n",
    "\n",
    "From this *true* process, we sample a 100 points\n",
    "\n",
    "Questions\n",
    "- What is a poisson process?\n",
    "$$y \\sim \\text{Poisson}(\\lambda) \\quad \\text{means} \\quad P(y=k) = \\frac{\\lambda^k e^{-k}}{k!} \\quad \\text{for} \\quad \\lambda > 0, k\\in \\mathbb{N}_{\\geq 0}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(seed=42)\n",
    "# Number of samples. \n",
    "n = 500\n",
    "# True rate parameter. \n",
    "rate_true = 2.0\n",
    "# Define Poisson distribution with the true rate parameter. \n",
    "poisson_true = tfd.Poisson(rate=rate_true)\n",
    "# Generate samples.\n",
    "poisson_samples = poisson_true.sample(sample_shape=n)\n",
    "poisson_samples;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_range, idy, c = tf.unique_with_counts(poisson_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "# sns.histplot(data=c.numpy())\n",
    "sns.barplot(x=y_range.numpy(),y=c.numpy(),color = 'skyblue',edgecolor='k',ax=ax)\n",
    "ax.xaxis.set_major_formatter(FormatStrFormatter('%.0f'))\n",
    "ax.set(title=f'Poisson Samples Distribution (num_samples = {n}, rate_true = {rate_true})');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the samples we have to tell what distribution there is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y \\sim \\text{Poisson}(\\lambda) \\quad \\text{with} \\quad \\lambda \\sim \\Gamma(a, b)$$\n",
    "\n",
    "That means, here we assume some prior distribution of the parameter lambda.\n",
    "From that distribution we will sample ten thousand values.\n",
    "For each of that prior we do two things:\n",
    "- Compute the probability of the prior\n",
    "- Compute the likelihood of the model given that prior\n",
    "\n",
    "Questions:\n",
    "\n",
    "- What is a gamma distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for the prior distribution. \n",
    "a = 4.5\n",
    "b = 2\n",
    "# Define prior distribution. \n",
    "gamma_prior = tfd.Gamma(concentration=a, rate=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples for the prior?\n",
    "gamma_prior_samples = gamma_prior.sample(sample_shape=1e4)\n",
    "# plotting\n",
    "fig,ax = plt.subplots(figsize=(10,6))\n",
    "sns.histplot(data=gamma_prior_samples,ax=ax,stat=\"density\")\n",
    "\n",
    "# Some density?\n",
    "# Plot density function of the gamma density.\n",
    "x = np.linspace(start=0, stop=10, num=100)\n",
    "sns.lineplot(\n",
    "    x=x,\n",
    "    lw=4,\n",
    "    y = gamma_prior.prob(x),\n",
    "    color=sns_c[1], \n",
    "    label='gamma_density', \n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Some Stats.\n",
    "sample_mean = tf.reduce_mean(gamma_prior_samples)\n",
    "sample_median = tfp.stats.percentile(x=gamma_prior_samples, q=50)\n",
    "\n",
    "ax.axvline(\n",
    "    x=sample_mean, \n",
    "    color=sns_c[1], \n",
    "    linestyle='--', \n",
    "    label=f'sample mean={sample_mean: 0.2f}'\n",
    ")\n",
    "\n",
    "ax.axvline(\n",
    "    x=sample_median, \n",
    "    color=sns_c[1], \n",
    "    linestyle=':', \n",
    "    label=f'sample median = {sample_median: 0.2f}'\n",
    ")\n",
    "\n",
    "ax.legend()\n",
    "ax.set(title=f'Prior Gamma Distribution (a={a}, b={b})');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior predictive sampling\n",
    "\n",
    "What does this even mean?\n",
    "\n",
    "y_prior_pred = tfd.Poisson(rate=gamma_prior_samples).sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prior_pred = tfd.Poisson(rate=gamma_prior_samples).sample(1)\n",
    "y_prior_pred = tf.reshape(y_prior_pred,-1)\n",
    "y_range_prior, idy_prior, c_prior = tf.unique_with_counts(y_prior_pred)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10,6))\n",
    "ax2 = ax1.twinx() \n",
    "\n",
    "sns.barplot(\n",
    "    x=y_range.numpy(), \n",
    "    y=c.numpy(), \n",
    "    color=sns_c[0], \n",
    "    edgecolor=sns_c[0], \n",
    "    alpha=0.7, \n",
    "    label='Sample Data Distribution', \n",
    "    ax=ax2\n",
    ")\n",
    "sns.barplot(\n",
    "    x=y_range_prior.numpy(), \n",
    "    y=c_prior.numpy(), \n",
    "    color=sns_c[1], \n",
    "    edgecolor=sns_c[1], \n",
    "    label='Prior Predictive Sample Data Distribution', \n",
    "    alpha=0.7, \n",
    "    ax=ax1\n",
    ")\n",
    "ax1.set(title=f'Poisson Samples (Sample Data & Prior Predictive Samples)')\n",
    "ax1.tick_params(axis='y', labelcolor=sns_c[1])\n",
    "ax1.xaxis.set_major_formatter(FormatStrFormatter('%.0f'))\n",
    "ax1.legend(loc='upper right')\n",
    "ax2.grid(None)\n",
    "ax2.legend(bbox_to_anchor=(0.84, 0.92))\n",
    "ax2.tick_params(axis='y', labelcolor=sns_c[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the inference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we set the model specification. \n",
    "def build_model(a=4.5, b=2):\n",
    "    # Prior Distribution.\n",
    "    # a and b here are 'hyper-parameters'\n",
    "    rate = tfd.Gamma(concentration=a, rate=b)\n",
    "    # Likelihood: Independent samples of a Poisson distribution. \n",
    "    observations = lambda rate: tfd.Sample(\n",
    "        distribution=tfd.Poisson(rate=rate), \n",
    "        sample_shape=len(poisson_samples)\n",
    "    )\n",
    "    return tfd.JointDistributionNamed(dict(rate=rate, obs=observations))\n",
    "    \n",
    "# We set the joint-log-probability as the target variable we want to maximize. \n",
    "def target_log_prob_fn(rate):\n",
    "    model = build_model()\n",
    "    return model.log_prob(rate=rate, obs=poisson_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid space search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define rates range.\n",
    "rates = np.linspace(start=0.01, stop=10.0, num=1000)\n",
    "\n",
    "# Compute joint-log-probability.\n",
    "model_log_probs = np.array([\n",
    "    target_log_prob_fn(rate).numpy() \n",
    "    for rate in rates\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rate which maximizes the log-probability of the model. \n",
    "log_prob_maximizer = rates[np.argmax(model_log_probs)]\n",
    "\n",
    "# Plot the results. \n",
    "fig, ax = plt.subplots() \n",
    "sns.lineplot(x=rates, y=model_log_probs, color=sns_c[0], label='model_log_prob', ax=ax)\n",
    "ax.axvline(x=rate_true, linestyle='--', color=sns_c[3], label=f'rate_true = {rate_true: 0.2f}')\n",
    "ax.axvline(x=log_prob_maximizer , linestyle='--', color=sns_c[1], label=f'log-prob-maximizer: {log_prob_maximizer: 0.2f}')\n",
    "ax.legend(loc='upper right')\n",
    "ax.set(title='Model Log Probability', xlabel='rate', ylabel='log probability');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hamilton Monte Carlo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of each chain.\n",
    "num_results = int(1e4)\n",
    "# Burn-in steps.\n",
    "num_burnin_steps = int(1e3)\n",
    "# Hamiltonian Monte Carlo transition kernel. \n",
    "# In TFP a TransitionKernel returns a new state given some old state.\n",
    "hcm_kernel  = tfp.mcmc.HamiltonianMonteCarlo(\n",
    "  target_log_prob_fn=target_log_prob_fn,\n",
    "  step_size=1.0,\n",
    "  num_leapfrog_steps=3\n",
    "  \n",
    ")\n",
    "# This adapts the inner kernel's step_size.\n",
    "adaptive_hmc = tfp.mcmc.SimpleStepSizeAdaptation(\n",
    "  inner_kernel = hcm_kernel,\n",
    "  num_adaptation_steps=int(num_burnin_steps * 0.8)\n",
    ")\n",
    "# Run the chain (with burn-in).\n",
    "@tf.function\n",
    "def run_chain():\n",
    "  # Run the chain (with burn-in). \n",
    "  # Implements MCMC via repeated TransitionKernel steps.\n",
    "  samples, is_accepted = tfp.mcmc.sample_chain(\n",
    "      num_results=num_results,\n",
    "      num_burnin_steps=num_burnin_steps,\n",
    "      current_state=1.0,\n",
    "      kernel=adaptive_hmc,\n",
    "      trace_fn=lambda _, pkr: pkr.inner_results.is_accepted\n",
    "    )\n",
    "  return samples,is_accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chains = 5\n",
    "chains = []\n",
    "for i in range(num_chains):\n",
    "    this, that = run_chain()\n",
    "    chains.append(this[that])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try without running this\n",
    "# \n",
    "chains = [j[:min(len(i) for i in chains)] for j in chains]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "for chain in chains:\n",
    "    sns.histplot(data=chain,ax=ax,stat='density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We store the samples in a pandas dataframe.\n",
    "chains_df = pd.DataFrame([t.numpy() for t in chains])\n",
    "chains_df = chains_df.T.melt(var_name='chain_id', value_name='sample')\n",
    "chains_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains_df.query(f'chain_id == {1}').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(10, 8))\n",
    "\n",
    "for i in range(5):\n",
    "    chain_samples = chains_df \\\n",
    "        .query(f'chain_id == {i}') \\\n",
    "        .reset_index(drop=True) \\\n",
    "        ['sample']\n",
    "\n",
    "    chain_samples_mean = chain_samples.mean()\n",
    "    chain_samples_std = chain_samples.std()\n",
    "    chain_samples_plus = chain_samples_mean + 2*chain_samples_std\n",
    "    chain_samples_minus = chain_samples_mean - 2*chain_samples_std\n",
    "\n",
    "    sns.histplot(data=chain_samples, color=sns_c[i], label=f'chain_{i}',kde=True, ax=ax[0])\n",
    "    ax[0].axvline(x=chain_samples_plus, linestyle='--', color=sns_c[i], label=f'chain_{i}_plus = {chain_samples_plus: 0.2f}')\n",
    "    ax[0].axvline(x=chain_samples_minus, linestyle='--', color=sns_c[i], label=f'chain_{i}_minus = {chain_samples_minus: 0.2f}')\n",
    "    ax[1].plot(chain_samples, c=sns_c[i], alpha=0.4)\n",
    "    ax[1].axhline(y=chain_samples_mean, linestyle='--', color=sns_c[i], label=f'chain_{i} mean = {chain_samples_mean: 0.2f}')\n",
    "\n",
    "ax[0].legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax[0].set(xlabel='rate', ylabel='')\n",
    "ax[1].legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax[1].set(xlabel='sample', ylabel='rate')\n",
    "plt.suptitle('Hamiltonian Monte Carlo Chains', y=0.92);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2,figsize=(14,4))\n",
    "\n",
    "chain_samples = chains_df['sample']\n",
    "chain_samples_mean = chain_samples.mean()\n",
    "chain_samples_std = chain_samples.std()\n",
    "chain_samples_plus = chain_samples_mean + 2*chain_samples_std\n",
    "chain_samples_minus = chain_samples_mean - 2*chain_samples_std\n",
    "\n",
    "sns.histplot(data=chain_samples, color=sns_c[9], label=f'chains samples', ax=ax[0])\n",
    "ax[0].axvline(x=chain_samples_plus, linestyle='--', color=sns_c[4], label=f'$\\mu + 2\\sigma$ = {chain_samples_plus: 0.2f}')\n",
    "ax[0].axvline(x=chain_samples_minus, linestyle='--', color=sns_c[4], label=f'$\\mu - 2\\sigma$ = {chain_samples_minus: 0.2f}')\n",
    "ax[1].plot(chain_samples, c=sns_c[9], alpha=0.7)\n",
    "ax[1].axhline(y=chain_samples_mean, linestyle='--', color=sns_c[0], label=f'$\\mu$ = {chain_samples_mean: 0.2f}')\n",
    "\n",
    "ax[0].legend(loc='upper right')\n",
    "ax[1].legend(loc='upper right')\n",
    "plt.suptitle(f'Posterior Distribution (Rate)', y=0.92);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_post_pred = tfd.Poisson(rate=chains_df['sample']).sample(1)\n",
    "y_post_pred  = tf.reshape(y_post_pred, [-1])\n",
    "\n",
    "y_range_prior, idy_prior, c_prior = tf.unique_with_counts(y_post_pred)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(12,6))\n",
    "ax2 = ax1.twinx() \n",
    "sns.barplot(\n",
    "    x=y_range.numpy(), \n",
    "    y=c.numpy(), \n",
    "    color=sns_c[0], \n",
    "    edgecolor=sns_c[0], \n",
    "    alpha=0.7, \n",
    "    label='Sample Data Distribution', \n",
    "    ax=ax2\n",
    ")\n",
    "sns.barplot(\n",
    "    x=y_range_prior.numpy(), \n",
    "    y=c_prior.numpy(), \n",
    "    color=sns_c[2], \n",
    "    edgecolor=sns_c[2], \n",
    "    label='Posterior Predictive Sample Data Distribution', \n",
    "    alpha=0.7, \n",
    "    ax=ax1\n",
    ")\n",
    "ax1.set(title=f'Poisson Samples (Sample Data & Prior Predictive Samples)')\n",
    "ax1.tick_params(axis='y', labelcolor=sns_c[1])\n",
    "ax1.xaxis.set_major_formatter(FormatStrFormatter('%.0f'))\n",
    "ax1.legend(loc='upper right')\n",
    "ax2.grid(None)\n",
    "ax2.legend(bbox_to_anchor=(0.8, 0.92))\n",
    "ax2.tick_params(axis='y', labelcolor=sns_c[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
