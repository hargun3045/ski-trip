{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes for Varshini\n",
    "\n",
    "1. Changed pre-processing because learning with MSE has these issues\n",
    " - Hard to train \n",
    " - Need to sum across pixels and not take the mean\n",
    " \n",
    "2. Changed the architecture bc.\n",
    " - KL divergence is low, but reconstruction error still very high\n",
    " \n",
    "3. Changed input shape from $(28,28)$ to $(28,28,1)$ because using conv layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Oky2mXp_t1jZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as p\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import layers, models, optimizers, regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "id": "ZdL7eKx2Riq4"
   },
   "outputs": [],
   "source": [
    "# GET THE MNIST DATA\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to \n",
    "# 1. Change dimensions\n",
    "# 2. Change datatype\n",
    "def binary_preprocess(imageset):\n",
    "    imageset = imageset.reshape(imageset.shape[0],28,28,1)/255.\n",
    "    return np.where(imageset > .5, 1.0,0.0).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processed images \n",
    "x_train_images = binary_preprocess(x_train)\n",
    "x_test_images = binary_preprocess(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset object to get a mini-batch\n",
    "batch_size = 32\n",
    "train_size = x_train_images.shape[0]\n",
    "train_dataset = (tf.data.Dataset.from_tensor_slices(x_train_images)\n",
    "                 .shuffle(train_size).batch(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "id": "ZyuVnihrv0Aa"
   },
   "outputs": [],
   "source": [
    "def get_encoder():\n",
    "  # THE ENCODER DEFINITION\n",
    "    encoded = tf.keras.models.Sequential(\n",
    "          [\n",
    "            tf.keras.layers.InputLayer(input_shape=(28, 28, 1)),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            # No activation\n",
    "            tf.keras.layers.Dense(4),\n",
    "        ]\n",
    "    )\n",
    "    return encoded\n",
    "\n",
    "\n",
    "def get_decoder():\n",
    "    decoded = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(2,)),\n",
    "            tf.keras.layers.Dense(units=7*7*32, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Reshape(target_shape=(7, 7, 32)),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=64, kernel_size=3, strides=2, padding='same',\n",
    "                activation='relu'),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=32, kernel_size=3, strides=2, padding='same',\n",
    "                activation='relu'),\n",
    "            # No activation\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=1, kernel_size=3, strides=1, padding='same'),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return decoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminology \n",
    "\n",
    "- mean is $\\mu$\n",
    "- variance is $\\sigma^2$\n",
    "- std deviation is $\\sigma$\n",
    "- $\\log{\\sigma}$ = $\\frac{1}{2}{log{\\sigma^2}}$\n",
    "- $\\sigma$ = $\\exp({\\frac{1}{2}{log{\\sigma^2}}})$\n",
    "- - $\\log{\\sigma^2}$ = $2{log{\\sigma}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding step\n",
    "# Get the mean and the variance\n",
    "def encode(encoder,x):\n",
    "    activations = encoder(x)\n",
    "    mean, variance = tf.split(activations,num_or_size_splits=2,axis=1)\n",
    "    return mean,variance\n",
    "\n",
    "# Reparametrization step\n",
    "def sample(mu, logvar):\n",
    "    e = tf.random.normal(shape=mu.shape)\n",
    "    return e * tf.exp(logvar/2) + mu\n",
    "\n",
    "# Combine the autoencoder\n",
    "def autoencoder(encoder,decoder,x):\n",
    "    mean,logvariance = encode(encoder,x)\n",
    "    z = sample(mean,logvariance)\n",
    "    output = decoder(z)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Be careful\n",
    "\n",
    "1. What is `sample` above?\n",
    "\n",
    "2. What is the PDF of a normal distribution?\n",
    "\n",
    "$$\n",
    "f(x)=\\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^{2}}\n",
    "$$\n",
    "\n",
    "3. Mean squared error is not the right approach. Because we assume each is normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, variance = encode(harencoder,x_train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(60000, 2), dtype=float32, numpy=\n",
       "array([[ 0.2548442 ,  0.07210281],\n",
       "       [ 1.7183516 , -1.2550998 ],\n",
       "       [ 0.02361488,  0.9139986 ],\n",
       "       ...,\n",
       "       [-1.3921298 ,  1.1864004 ],\n",
       "       [ 1.8548329 ,  1.2522751 ],\n",
       "       [-0.3437529 , -0.62872946]], dtype=float32)>"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick way to get the log likelihood of a normal distribution\n",
    "def log_normal_pdf(value, mean, logvar, raxis=1):\n",
    "    log_2pi = tf.math.log(2. * np.pi)\n",
    "    logpdf = -(logvar + log_2pi + (value - mean)**2. * tf.exp(-logvar))/2\n",
    "    return tf.reduce_sum(logpdf,axis=1)\n",
    "\n",
    "# Loss over the assumed distribution(qz_x) and the prior(pz)\n",
    "def kl_loss(encoder, x):\n",
    "    mean, logvar = encode(encoder,x)\n",
    "    z = sample(mean,logvar)\n",
    "    logpz = log_normal_pdf(z, 0., 0.)\n",
    "    logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "    return tf.reduce_mean(logqz_x - logpz)\n",
    "\n",
    "# This is now binary cross entropy\n",
    "# Crucially, observe that we sum across the image dimensions\n",
    "# and only take the mean in the images dimension\n",
    "def reconstruction_loss(encoder,decoder,x):\n",
    "    x_logits = autoencoder(encoder,decoder,x)\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logits,labels=x)\n",
    "    return tf.reduce_mean(tf.reduce_sum(loss,axis=[1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "\n",
    "# Instantiate an optimizerc\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "# Define number of epochs\n",
    "num_epochs = 10\n",
    "harencoder = get_encoder()\n",
    "hardecoder = get_decoder()\n",
    "\n",
    "train_size = x_train_images.shape[0]\n",
    "batch_size = 32\n",
    "\n",
    "# Loop over the required number of epochs\n",
    "for i in range(num_epochs):\n",
    "    for i in range(int(train_size/batch_size)):\n",
    "        \n",
    "        x_train_batch = x_train_images[np.random.choice(train_size,batch_size)]\n",
    "        \n",
    "\n",
    "        with tf.GradientTape(persistent=True) as t:\n",
    "\n",
    "            decoder_output = autoencoder(harencoder,hardecoder,x_train_batch)\n",
    "\n",
    "            L1 = reconstruction_loss(encoder,decoder,x_train_batch)\n",
    "            L2 = kl_loss(encoder,x_train_batch)\n",
    "            loss = L1 + L2\n",
    "        gradients1 = t.gradient(loss, decoder.trainable_weights)\n",
    "        gradients2 = t.gradient(loss, encoder.trainable_weights)\n",
    "\n",
    "        optimizer.apply_gradients(zip(gradients1, decoder.trainable_weights))\n",
    "        optimizer.apply_gradients(zip(gradients2, encoder.trainable_weights))\n",
    "\n",
    "          \n",
    "    print(f'Loss at epoch {i} is {loss:.2f}, KL Divergence is {L2:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x198b6bdf0>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Verify if there is some learning\n",
    "fig, ax = plt.subplots(1,2)\n",
    "\n",
    "# Prediction \n",
    "pred = tf.sigmoid(autoencoder(harencoder,hardecoder,x_test_images[0:1]))\n",
    "pred = pred.numpy().squeeze()\n",
    "\n",
    "ax[0].imshow(x_test_images[0].squeeze(),cmap='gray')\n",
    "ax[1].imshow(pred,cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "VAE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
