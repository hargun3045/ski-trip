{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4,
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# import required libraries\n",
                "\n",
                "from tensorflow.keras.datasets import mnist\n",
                "from tensorflow.keras.layers import Dense, Input, Flatten, Reshape\n",
                "from tensorflow.keras import models\n",
                "from tensorflow.keras.models import Model, Sequential\n",
                "from tensorflow.keras import layers\n",
                "from matplotlib import pyplot as plt\n",
                "from IPython import display \n",
                "import numpy as np\n",
                "\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_normalize) ###\n",
                "# First we load in the MNIST dataset.\n",
                "\n",
                "# Do not fill in the blank space\n",
                "(x_train, _), (x_test, _) = mnist.load_data()\n",
                "\n",
                "\n",
                "# We will only take 4000 data points from the original dataset to demonstrate the autoencoders\n",
                "sample_size = 4000 \n",
                "x_train = x_train[:sample_size]\n",
                "x_test = x_test[:sample_size]\n",
                "\n",
                "# We normalize the pixel data (i.e divide by 255)\n",
                "\n",
                "x_train = ___\n",
                "x_test = ___\n",
                "\n",
                "# We print image dimensions to confirm \n",
                "print(f'image shape: {x_train[0].shape} and random pixel value is {x_train[0][20][10]}')\n",
                "\n",
                "# We also plot example image from x_train\n",
                "plt.imshow(x_train[0], cmap = \"gray\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Now we create the encoder model to take compress each image down to a lower dimensional latent space.\n",
                "\n",
                "# pick a size for the latent dimension like 32\n",
                "latent_size = ___\n",
                "\n",
                "# Note how sequential models can also be passed a list of layers\n",
                "\n",
                "# This can be more concise than using add()\n",
                "model_1 = models.Sequential(name='Encoder')\n",
                "\n",
                "# add a flatten layer to convert image of size (28,28) to 784\n",
                "model_1.add(___)\n",
                "\n",
                "# add a dense layer with 128 neurons\n",
                "model_1.add(___)\n",
                "\n",
                "# add another dense layer with 64 neurons\n",
                "model_1.add(___)\n",
                "\n",
                "# Finally add the last dense layer with latent_size number of neurons\n",
                "model_1.add(___)\n",
                "\n",
                "# Take a quick look at the model summary\n",
                "model_1.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Now we create the decoder model to take compress each image down to a lower dimensional latent space.\n",
                "model_2 = models.Sequential(name='Decoder')\n",
                "\n",
                "# add a dense layer with 64 neurons\n",
                "model_2.add(___)\n",
                "\n",
                "# add a dense layer with 128 neurons\n",
                "model_2.add(___)\n",
                "\n",
                "# add a dense layer with 784 neurons and especially choose an appropriate activation function\n",
                "model_2.add(___)\n",
                "\n",
                "# finally reshape it back to size 28,28\n",
                "model_2.add(___)\n",
                "\n",
                "# Take a quick look at the model summary\n",
                "model_2.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# To build autoencoders, we will use the keras 'functional api'\n",
                "# read more here -\u003e https://www.tensorflow.org/guide/keras/functional\n",
                "\n",
                "# define an input of the dimension of the image\n",
                "img = Input(shape=(28,28))\n",
                "\n",
                "# Use the 'encoder' i.e model_1 from above to get a variable `latent_vector`\n",
                "latent_vector = model_1(___)\n",
                "\n",
                "# Use the 'decoder' i.e model_2 from above to get the output variable\n",
                "output = model_2(___)\n",
                "\n",
                "\n",
                "# using functional api to define autoencoder model\n",
                "autoencoder = Model(inputs = ___, outputs = ___)\n",
                "\n",
                "# choose an appropriate loss function for 'reconstruction error'\n",
                "autoencoder.compile(___)\n",
                "\n",
                "# Take a quick look at the model summary\n",
                "autoencoder.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# # You can train for 10 or more epochs to see how well our autoencoder model performs\n",
                "epochs = 10\n",
                "\n",
                "for i in range(epochs+1):\n",
                "# Note: epoch 0 is before any fitting\n",
                "    fig, axs = plt.subplots(1, 2,figsize = (8,4))\n",
                "    sample_x = x_test[np.random.choice(x_test.shape[0])]\n",
                "    axs[0].imshow(sample_x,cmap = \"gray\")\n",
                "    axs[0].set_title('Test image',fontsize = 16)\n",
                "    axs[1].imshow(autoencoder.predict(sample_x.reshape(1,28,28))[0],cmap = \"gray\")\n",
                "    axs[1].set_title('Autoencoder Prediction',fontsize = 16);\n",
                "    fig.suptitle(f'Autoencoder recreation after epoch number {i}',fontsize =14)\n",
                "    plt.show()\n",
                "    \n",
                "    # specify predictors and targets for train and validation and train for an epoch\n",
                "    \n",
                "    autoencoder.fit(x=x_train,\n",
                "                y=x_train,\n",
                "                validation_data=(x_test, x_test))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Mindchow üç≤\n",
                "\n",
                "Go back and change the `latent_space` dimension to a lower value like 2. Does your autoencoder's reconstructions become better or worse? Why?"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "*Your answer here*"
            ]
        }
    ]
}
